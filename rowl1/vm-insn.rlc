;
; rowl - 1st generation
; Copyright (C) 2010 nineties
;
; $Id: vm-insn.rlc 2012-11-25 12:44:48 nineties $
;

(define gen_field_get (idx) `(
    (asm "movl (%esi), %eax")
    (asm "movl " @(* 4 idx) "(%eax), %eax")
    (asm "movl %eax, (%esi)")
    ))

(define gen_field_set (idx) `(
    (vmpop %eax) ; ptr
    (asm "movl (%esi), %ecx") ; value
    (asm "movl %ecx, " @(* 4 idx) "(%eax)")
    ))

(define gen_comparison1 (cmovname) `(
    (vmpop %eax)
    (asm "cmpl %edx, %eax")
    (asm "movl $3, %eax")
    (vmsshort 1 %ecx)
    (asm @cmovname " %ecx, %eax")
    (vmsucc %eax)
    (vmfetch)
    ))

(define gen_comparison2 (cmovname) `(
    (vmpop %eax)
    (vmpop %ecx)
    (asm "cmpl %eax, %ecx")
    (asm "movl $3, %eax")
    (vmsshort 1 %ecx)
    (asm @cmovname " %ecx, %eax")
    (vmsucc %eax)
    (vmfetch)
    ))

(define gen_comparison3 (jmpname) `(
    (vmpop %eax)
    (vmpop %ecx)
    (asm "fldl (%eax)")
    (asm "fldl (%ecx)")
    (asm "fcompp")
    (asm "fstsw %ax")
    (asm "sahf")
    (asm @jmpname " 1f")
    (vmsucc 3)
    (vmfetch)
    (asm "1:")
    (vmsshort 1 %eax)
    (vmsucc %eax)
    (vmfetch)
    ))

(define gen_check_pstruct (type) `(
    (vmpop %eax)
    (asm "testl $1, %eax")
    (asm "jnz 1f")
    (asm "testl %eax, %eax")
    (asm "jz 1f")
    (asm "movl -4(%eax), %eax")
    ; XXX: should not hardcode the layout of object header.
    (asm "andl $" @(- (<< 1 11) 1) ", %eax")
    (asm "cmpl $" @(| (<< type 3) TAG_PSTRUCT) ", %eax")
    (asm "je 2f")
    (asm "1:")
    (vmsshort 1 %ecx)
    (vmsucc %ecx)
    (vmfetch)
    (asm "2:")
    (vmsucc 3)
    (vmfetch)
    ))

(define operand_len (opd) (assoc opd `((byte . 1) (short . 2) (ushort . 2) (int . 4) (prim . 2) (addr . 2) (laddr . 4) (object . 4))))
(define insn_length (operands) (do
    (var len 1) ; 1 for instruction code
    (foreach o operands (+= len (operand_len o)))
    len
    ))

(var vm_instructions `(
    (nop   () @true ())
    (drop  () @true ((asm "addl $4, %esi")))
    (drop2 () @true ((asm "addl $8, %esi")))
    (dup   () @true ((asm "movl (%esi), %eax") (vmpush %eax)))
    (swap  () @true (
        (asm "movl (%esi), %eax")
        (asm "movl 4(%esi), %ecx")
        (asm "movl %eax, 4(%esi)")
        (asm "movl %ecx, (%esi)")
        ))
    (imm_im1   () @true ((vmpush $-1)))
    (imm_i0    () @true ((vmpush %edx))) ; also used for 'nil'
    (imm_i1    () @true ((vmpush $1)))
    (imm_i2    () @true ((vmpush $2)))
    (imm_i3    () @true ((vmpush $3)))
    (imm_i4    () @true ((vmpush $4)))
    (imm_i5    () @true ((vmpush $5)))
    (imm_int16 (short) @true ((vmsshort 1 %eax) (vmpush %eax)))
    (imm_int32 (int) @true ((vmint 1 %eax) (vmpush %eax)))
    (iadd      () @true ((vmbin "addl")))
    (isub      () @true ((vmbin "subl")))
    (iadd1 () @true ((asm "addl $1, (%esi)")))
    (isub1 () @true ((asm "subl $1, (%esi)")))

    (ineg       () @true ((asm "negl (%esi)")))
    (imul      () @true ((vmpop %eax) (asm "imul (%esi), %eax") (asm "movl %eax, (%esi)")))

    ; signed
    (idiv      () @true (
        (asm "movl (%esi), %ecx")
        (asm "movl 4(%esi), %eax")
        (asm "cltd")
        (asm "idivl %ecx")
        (asm "testl %edx, %edx")
        (asm "jz 1f")
        (asm "movl (%esi), %ecx")
        (asm "xorl 4(%esi), %ecx")
        (asm "jns 1f")
        (asm "subl $1, %eax")
        (asm "1:")
        (asm "addl $4, %esi")
        (asm "movl %eax, (%esi)")
        (asm "xorl %edx, %edx") ; clear zero register
        ))
    (imod       () @true (
        (asm "movl (%esi), %ecx")
        (asm "movl 4(%esi), %eax")
        (asm "cltd")
        (asm "idivl %ecx")
        (asm "testl %edx, %edx")
        (asm "jz 1f")
        (asm "movl (%esi), %eax")
        (asm "xorl 4(%esi), %eax")
        (asm "jns 1f")
        (asm "addl %ecx, %edx")
        (asm "1:")
        (asm "addl $4, %esi")
        (asm "movl %edx, (%esi)")
        (asm "xorl %edx, %edx") ; clear zero register
        ))

    ; unsigned
    (udiv      () @true (
        (vmpop %ecx)
        (asm "movl (%esi), %eax")
        (asm "divl %ecx")
        (asm "movl %eax, (%esi)")
        (asm "xorl %edx, %edx") ; clear zero register
        ))
    (umod       () @true (
        (vmpop %ecx)
        (asm "movl (%esi), %eax")
        (asm "divl %ecx")
        (asm "movl %edx, (%esi)")
        (asm "xorl %edx, %edx") ; clear zero register
        ))

    ; long unsigned division (64-bit)/(32-bit)
    ; this instruction is required for division of big-integer
    ; 
    ; ludiv h l d = floor( (h*2^32 + l)/d )
    ; quotient must be less than 2^32
    (ludiv      () @true (
        (vmpop %ecx)
        (vmpop %eax)
        (asm "movl (%esi), %edx")
        (asm "divl %ecx")
        (asm "movl %eax, (%esi)")
        (asm "xorl %edx, %edx")
        ))

    (shl   () @true (
        (vmpop %ecx)
        (vmpop %eax)
        (asm "shll %cl, %eax")
        (vmpush %eax)
        ))
    (shr   () @true (
        (vmpop %ecx)
        (vmpop %eax)
        (asm "shrl %cl, %eax")
        (vmpush %eax)
        ))
    (sal   () @true (
        (vmpop %ecx)
        (vmpop %eax)
        (asm "sall %cl, %eax")
        (vmpush %eax)
        ))
    (sar   () @true (
        (vmpop %ecx)
        (vmpop %eax)
        (asm "sarl %cl, %eax")
        (vmpush %eax)
        ))
    (bsr   () @true (
        (asm "movl (%esi), %eax")
        (asm "bsr %eax, %eax")
        (asm "cmovz %edx, %eax")
        (asm "movl %eax, (%esi)")
        ))
    (and    () @true ((vmbin "andl")))
    (or     () @true ((vmbin "orl")))
    (xor    () @true ((vmbin "xorl")))

    (box       () @true (
        (asm "sall $1, (%esi)")
        (asm "addl $1, (%esi)")
        ))
    (unbox     () @true (
        (asm "sarl $1, (%esi)")
        ))

    ; bigint arithmetic
    ; 1st argument must be big-integer
    ; 2nd argument must be big-integer or fixed-integer
    ; no run-time check is performed
    (badd   () @true (
        (asm "pushl %ebx")

        (asm "movl (%esi), %eax") ; rhs
        (asm "movl 4(%esi), %ebx") ; lhs
        (asm "movl 12(%eax), %eax") ; sign of rhs
        (asm "cmpl 12(%ebx), %eax")
        (asm "jne bsub_main") ; if rhs and lhs has different signs, switch to bsub
        ; compute (stp) += (eax)
        (asm "badd_main:")
        (asm "movl (%esi), %eax")
        (asm "movl 4(%esi), %ebx")
        (asm "movl 4(%ebx), %ecx")  ; number of digits of lhs
        (asm "cmpl 4(%eax), %ecx")   
        (asm "cmovl 4(%eax), %ecx")
        (asm "addl $1, %ecx") ; ecx = max(lhs.ndigit, rhs.ndigit) + 1
        (asm "cmpl 8(%ebx), %ecx") ; compare capa of lhs and ecx
        (asm "jle 2f")
        ; reserve array of lhs
        (asm "pushl %eax")
        (vmsave)
        (asm "pushl %ecx")
        (asm "movl 4(%esi), %eax")
        (asm "pushl %eax")
        (asm "call prim_resize_bint")
        (asm "addl $8, %esp")
        (vmrestore)
        (asm "popl %eax")
        (asm "2:")

        (asm "movl 4(%eax), %ecx")  ; %ecx = number of digits of rhs
        (asm "movl (%eax), %eax")   ; %eax = digits of rhs
        (asm "movl (%ebx), %ebx")   ; %ebx = digits of lhs

        ; while ecx > 0 { *ebx++ += *eax++ with carry }
        (asm "4:")
        (asm "addl %edx, (%ebx)")
        (asm "movl (%eax), %edx")
        (asm "addl %edx, (%ebx)")
        (asm "movl $0, %edx")
        (asm "adcl %edx, %edx")
        (asm "subl $1, %ecx")
        (asm "addl $4, %eax")
        (asm "addl $4, %ebx")
        (asm "testl %ecx, %ecx")
        (asm "jnz 4b")
        (asm "5:")
        (asm "addl %edx, (%ebx)")
        (asm "movl $0, %edx")
        (asm "adcl %edx, %edx")
        (asm "addl $4, %ebx")
        (asm "testl %edx, %edx")
        (asm "jnz 5b")

        ; update number of digits
        (asm "movl 4(%esi), %ebx")
        (asm "movl 8(%ebx), %ecx")
        (asm "movl (%ebx), %ebx")
        (asm "leal -4(%ebx,%ecx,4), %ebx")
        (asm "6:")
        (asm "movl (%ebx), %eax")
        (asm "testl %eax, %eax")
        (asm "jnz 8f")
        (asm "subl $1, %ecx")
        (asm "testl %ecx, %ecx")
        (asm "jz 7f")
        (asm "subl $4, %ebx")
        (asm "jmp 6b")
        (asm "7:")
        (asm "addl $1, %ecx")
        (asm "8:")
        (asm "movl 4(%esi), %ebx")
        (asm "movl %ecx, 4(%ebx)")

        (asm "xorl %edx, %edx")
        (asm "addl $4, %esi")
        (asm "popl %ebx")
        ))
    (bsub   () @true (
        (asm "pushl %ebx")

        (asm "movl (%esi), %eax") ; rhs
        (asm "movl 4(%esi), %ebx") ; lhs
        (asm "movl 12(%eax), %eax") ; sign of rhs
        (asm "cmpl 12(%ebx), %eax")
        (asm "jne badd_main") ; if rhs and lhs has different signs, switch to badd

        (asm "bsub_main:")
        (asm "movl (%esi), %eax")
        (asm "movl 4(%esi), %ebx")
        (asm "movl 4(%ebx), %ecx")  ; number of digits of lhs
        (asm "cmpl 4(%eax), %ecx")   
        (asm "cmovl 4(%eax), %ecx") ; max(lhs.ndigit, rhs.ndigit)
        (asm "cmpl 8(%ebx), %ecx") ; compare capa of lhs and ecx
        (asm "jle 2f")
        ; reserve array of lhs
        (asm "pushl %eax")
        (vmsave)
        (asm "pushl %ecx")
        (asm "movl 4(%esi), %eax")
        (asm "pushl %eax")
        (asm "call prim_resize_bint")
        (asm "addl $8, %esp")
        (vmrestore)
        (asm "popl %eax")
        (asm "2:")

        ; === compute lhs -= rhs) === 
        ; 1. compare lhs.abs and rhs.abs
        (asm "movl 4(%ebx), %ecx")  ; ebx = lhs, eax = rhs
        (asm "cmpl 4(%eax), %ecx")  ; rhs.ndigit <=> lhs.ndigit
        (asm "ja 3f")
        (asm "jb 4f")
        (asm "movl (%ebx), %ebx")
        (asm "movl (%eax), %eax")
        (asm "subl $1, %ecx")
        (asm "leal (%eax,%ecx,4), %eax")
        (asm "leal (%ebx,%ecx,4), %ebx")
        (asm "5:")

        (asm "movl (%ebx), %edx")
        (asm "cmpl (%eax), %edx")   ; rhs.digits[ecx] <=> lhs.digits[ecx] 
        (asm "ja 3f")
        (asm "jb 4f")
        (asm "subl $1, %ecx")
        (asm "testl %ecx, %ecx")
        (asm "jnz 5b")

        ; 2. do computation
        (asm "3:") ; lhs.abs >= rhs.abs
        (asm "movl (%esi), %eax")
        (asm "movl 4(%esi), %ebx")
        (asm "movl 4(%eax), %ecx") ; rhs.ndigit
        (asm "movl (%eax), %eax") ; rhs.digits
        (asm "movl (%ebx), %ebx") ; lhs.digits
        (asm "xorl %edx, %edx") ; clear edx

        (asm "6:")
        (asm "subl %edx, (%ebx)")
        (asm "movl (%eax), %edx")
        (asm "subl %edx, (%ebx)")
        (asm "movl $0, %edx")
        (asm "adcl %edx, %edx")
        (asm "subl $1, %ecx")
        (asm "addl $4, %eax")
        (asm "addl $4, %ebx")
        (asm "testl %ecx, %ecx")
        (asm "jnz 6b")
        (asm "7:")
        (asm "testl %edx, %edx")
        (asm "jz 8f")
        (asm "subl %edx, (%ebx)")
        (asm "movl $0, %edx")
        (asm "adcl %edx, %edx")
        (asm "addl $4, %ebx")
        (asm "jmp 7b")

        (asm "4:") ; lhs.abs < rhs.abs
        (asm "subl $4, %esp")
        (asm "movl (%esi), %eax")
        (asm "movl 4(%esi), %ebx")
        (asm "xorl $1, 12(%ebx)") 
        (asm "movl 4(%eax), %ecx")
        (asm "movl %ecx, (%esp)") ; rhs.ndigit
        (asm "movl 4(%ebx), %ecx") ; lhs.ndigit
        (asm "movl (%eax), %eax") ; rhs.digits
        (asm "movl (%ebx), %ebx") ; lhs.digits
        (asm "xorl %edx, %edx") ; clear edx

        (asm "12:")
        (asm "addl %edx, (%ebx)")
        (asm "movl (%eax), %edx")
        (asm "subl (%ebx), %edx")
        (asm "movl %edx, (%ebx)")
        (asm "movl $0, %edx")
        (asm "adcl %edx, %edx")
        (asm "subl $1, %ecx")
        (asm "subl $1, (%esp)")
        (asm "addl $4, %eax")
        (asm "addl $4, %ebx")
        (asm "testl %ecx, %ecx")
        (asm "jnz 12b")

        (asm "13:")
        (asm "movl (%esp), %ecx")
        (asm "testl %ecx, %ecx")
        (asm "jz 14f")

        (asm "movl (%eax), %ecx")
        (asm "subl %edx, %ecx")
        (asm "movl %ecx, (%ebx)")
        (asm "movl $0, %edx")
        (asm "adcl %edx, %edx")
        (asm "subl $1, (%esp)")
        (asm "addl $4, %eax")
        (asm "addl $4, %ebx")
        (asm "jmp 13b")

        (asm "14:")
        (asm "addl $4, %esp")
        (asm "8:")
        ; update number of digits
        (asm "movl 4(%esi), %ebx")
        (asm "movl 8(%ebx), %ecx")
        (asm "movl (%ebx), %ebx")
        (asm "leal -4(%ebx,%ecx,4), %ebx")
        (asm "9:")
        (asm "movl (%ebx), %eax")
        (asm "testl %eax, %eax")
        (asm "jnz 11f")
        (asm "subl $1, %ecx")
        (asm "testl %ecx, %ecx")
        (asm "jz 10f")
        (asm "subl $4, %ebx")
        (asm "jmp 9b")
        (asm "10:")
        (asm "addl $1, %ecx")
        (asm "11:")
        (asm "movl 4(%esi), %ebx")
        (asm "movl %ecx, 4(%ebx)")

        (asm "xorl %edx, %edx")
        (asm "addl $4, %esi")
        (asm "popl %ebx")
        ))
    (bmul   () @true (
        (asm "pushl %ebx")

        (asm "movl (%esi), %eax") ; rhs
        (asm "movl 4(%esi), %ebx") ; lhs
        (asm "movl 12(%eax), %eax"); sign of rhs
        (asm "xorl %eax, 12(%ebx)")

        (asm "movl 4(%ebx), %ecx") ; lhs.ndigit
        (asm "movl (%esi), %eax")
        (asm "imul 4(%eax), %ecx")
        (asm "addl $1, %ecx") ; lhs.ndigit * rhs.ndigit + 1
        ; allocate array for result

        (vmsave)
        (asm "pushl %ecx")
        (asm "call prim_allocate_iarray")
        (asm "addl $4, %esp")
        (vmrestore)

        ; setup variables
        (asm "subl $8, %esp")
        (asm "pushl %eax")        ; working array
        (asm "pushl 4(%ebx)")     ; lhs.ndigit
        (asm "pushl (%ebx)")      ; lhs.digits
        (asm "movl (%esi), %ebx")
        (asm "pushl 4(%ebx)")     ; rhs.ndigit
        (asm "pushl (%ebx)")      ; rhs.digits
        (asm "pushl $0")          ; index for rhs.digits
        (asm "pushl $0")          ; index for lhs.digits

        ; variable table
        ;   (%esp) : (i) index for lhs.digits
        ;  4(%esp) : (j) index for rhs.digits
        ;  8(%esp) : (v) rhs.digits
        ; 12(%esp) : (m) rhs.ndigit
        ; 16(%esp) : (u) lhs.digits
        ; 20(%esp) : (n) lhs.ndigit
        ; 24(%esp) : (w) working array
        ; 28(%esp) : v[j]
        ; 32(%esp) : working area

        (asm "1:")
        (asm "movl 4(%esp), %eax")
        (asm "cmpl %eax, 12(%esp)")
        (asm "je 4f") ; exit if j == m

        (asm "movl 8(%esp), %ebx")
        (asm "leal (%ebx, %eax, 4), %ebx")
        (asm "movl (%ebx), %ebx") ; ebx = v[j]
        (asm "movl %ebx, 28(%esp)")

        (asm "movl $0, (%esp)") ; i = 0
        (asm "xorl %ecx, %ecx")  ; carry = 0

        (asm "2:")

        (asm "movl (%esp), %eax")
        (asm "cmpl %eax, 20(%esp)")
        (asm "je 3f") ; exit if i == n

        (asm "movl 16(%esp), %ebx")
        (asm "leal (%ebx, %eax, 4), %eax")
        (asm "movl (%eax), %eax") ; eax = u[i]
        (asm "mull 28(%esp)") ; %edx:%eax = u[i] * v[j]
        (asm "addl %ecx, %eax") ; add carry
        (asm "adcl $0, %edx")

        (asm "movl %eax, 32(%esp)")

        (asm "movl (%esp), %eax")
        (asm "addl 4(%esp), %eax") ; eax = i + j
        (asm "movl 24(%esp), %ebx")
        (asm "leal (%ebx,%eax,4), %ecx")
        (asm "movl (%ecx), %ecx") ; ecx = w[i+j]
        (asm "addl %ecx, 32(%esp)")
        (asm "adcl $0, %edx")
        (asm "movl %edx, %ecx")
        (asm "movl 32(%esp), %edx")
        (asm "leal (%ebx, %eax, 4), %eax")
        (asm "movl %edx, (%eax)")

        (asm "addl $1, (%esp)")
        (asm "jmp 2b")

        (asm "3:")
        (asm "movl 4(%esp), %eax")
        (asm "addl 20(%esp), %eax") ; eax = n + j
        (asm "movl 24(%esp), %ebx")
        (asm "leal (%ebx, %eax, 4), %eax")
        (asm "movl %ecx, (%eax)")

        (asm "addl $1, 4(%esp)")
        (asm "jmp 1b")
        (asm "4:")

        ; w is the result
        (asm "movl 4(%esi), %eax") ; lhs
        (asm "movl 24(%esp), %ebx")
        (asm "movl %ebx, (%eax)")

        ; update lhs.ndigit
        (asm "movl 12(%esp), %ecx")
        (asm "imul 20(%esp), %ecx")
        (asm "addl $1, %ecx")
        (asm "movl %ecx, 8(%eax)")

        (asm "movl (%eax), %eax")
        (asm "leal -4(%eax,%ecx,4), %ebx")
        (asm "9:")
        (asm "movl (%ebx), %eax")
        (asm "testl %eax, %eax")
        (asm "jnz 11f")
        (asm "subl $1, %ecx")
        (asm "testl %ecx, %ecx")
        (asm "jz 10f")
        (asm "subl $4, %ebx")
        (asm "jmp 9b")
        (asm "10:")
        (asm "addl $1, %ecx")
        (asm "11:")
        (asm "movl 4(%esi), %ebx")
        (asm "movl %ecx, 4(%ebx)")

        (asm "addl $36, %esp")

        (asm "addl $4, %esi")
        (asm "xorl %edx, %edx")
        (asm "popl %ebx")
        ))

    (bcmp () @true (
        (asm "pushl %ebx")

        (asm "movl (%esi), %eax")   ; rhs
        (asm "movl 4(%esi), %ebx")  ; lhs
        (asm "movl 12(%eax), %eax") ; rhs.sign
        (asm "subl 12(%ebx), %eax") ; rhs.sign - lhs.sign
        (asm "jz 1f")
        (asm "movl %eax, 4(%esi)")
        (asm "jmp 2f")
        (asm "1:") ; rhs.sign == lhs.sign
        (asm "movl (%esi), %eax")  ; rhs
        (asm "movl 4(%esi), %ebx") ; lhs
        (asm "movl 4(%eax), %ecx") ; rhs.ndigit
        (asm "cmpl 4(%ebx), %ecx") ; rhs.ndigit - lhs.ndigit
        (asm "ja 3f")
        (asm "jb 4f")

        ; lhs.ndigit == rhs.ndigit
        (asm "6:")
        (asm "testl %ecx, %ecx")
        (asm "jz 7f")
        (asm "subl $1, %ecx")
        (asm "movl (%esi), %eax")
        (asm "movl 4(%esi), %ebx")
        (asm "movl (%eax), %eax") ; rhs.digits
        (asm "movl (%ebx), %ebx") ; lhs.digits
        (asm "leal (%eax,%ecx,4), %eax")
        (asm "leal (%ebx,%ecx,4), %ebx")
        (asm "movl (%eax), %edx")
        (asm "cmpl (%ebx), %edx") ; rhs.digit[ecx] - lhs.digit[ecx]
        (asm "ja 3f")
        (asm "jb 4f")
        (asm "jmp 6b")
        (asm "7:")
        (asm "movl $0, 4(%esi)")
        (asm "jmp 2f")
        (asm "3:") ; |lhs| < |rhs|
        (asm "movl $-1, 4(%esi)")
        (asm "jmp 5f")
        (asm "4:") ; |rhs| < |lhs|
        (asm "movl $1, 4(%esi)")
        (asm "5:")
        (asm "movl (%esi), %eax")
        (asm "cmp $0, 12(%eax)")
        (asm "je 2f")
        (asm "negl 4(%esi)")
        (asm "2:")

        (asm "addl $4, %esi")
        (asm "xorl %edx, %edx")
        (asm "popl %ebx")
        ))
    (bshl () @true (
        (asm "pushl %ebx")
        (asm "movl (%esi), %ecx")  ; shift length
        (asm "shrl $5, %ecx")      ; ecx = ecx/32
        (asm "movl 4(%esi), %eax") ; x
        (asm "movl 4(%eax), %ebx") ; x.ndigit
        (asm "addl %ecx, %ebx")    ; x.ndigit + ecx
        (asm "addl $1, %ebx")
        (asm "cmpl 8(%eax), %ebx") ; (x.ndigit + ecx + 1) <=> x.capa
        (asm "jbe 1f")
        (vmsave)
        (asm "pushl %ecx")
        (asm "pushl %ebx")
        (asm "pushl %eax")
        (asm "call prim_resize_bint")
        (asm "addl $8, %esp")
        (asm "popl %ecx")
        (vmrestore)
        (asm "1:")

        (asm "testl %ecx, %ecx")
        (asm "jz 10f") 
        ; shift (%esi) / 32
        (asm "movl 4(%esi), %eax") ; x
        (asm "movl (%eax), %ebx")  ; x.digits
        (asm "movl 4(%eax), %edx") ; x.ndigit
        (asm "addl %edx, %ecx")
        (asm "subl $4, %esp") ; copy of edx
        (asm "movl %edx, (%esp)")
        (asm "2:")
        (asm "movl (%esp), %edx")
        (asm "testl %edx, %edx")
        (asm "jz 3f")
        (asm "subl $1, (%esp)")
        (asm "movl (%esp), %edx")
        (asm "subl $1, %ecx")
        (asm "leal (%ebx,%edx,4), %edx")
        (asm "leal (%ebx,%ecx,4), %eax")
        (asm "movl (%edx), %edx")
        (asm "movl %edx, (%eax)")
        (asm "jmp 2b")
        (asm "3:")
        (asm "testl %ecx, %ecx")
        (asm "jz 4f")
        (asm "subl $1, %ecx")
        (asm "leal (%ebx,%ecx,4), %eax")
        (asm "movl $0, (%eax)")
        (asm "jmp 3b")
        (asm "4:")
        (asm "addl $4, %esp")
        (asm "10:")

        ; shift (%esi) % 32
        (asm "subl $8, %esp")
        (asm "movl 4(%esi), %ebx")
        (asm "movl (%ebx), %eax")
        (asm "movl %eax, (%esp)")
        (asm "movl 4(%ebx), %eax")
        (asm "movl (%esi), %ecx")
        (asm "shrl $5, %ecx")
        (asm "addl %ecx, %eax")
        (asm "addl $1, %eax")
        (asm "movl %eax, 4(%esp)")  
        (asm "movl (%esi), %ecx")
        (asm "andl $0x1f, %ecx") ; ecx = (shift length) % 32

        ; (%esp) : x.digits
        ; 4(%esp): x.ndigit

        (asm "5:")
        (asm "movl 4(%esp), %ebx")
        (asm "cmpl $1, %ebx")
        (asm "je 6f")
        (asm "subl $1, 4(%esp)")
        (asm "movl 4(%esp), %ebx")
        (asm "movl (%esp), %edx")
        (asm "leal (%edx,%ebx,4), %eax")
        (asm "leal -4(%edx,%ebx,4), %edx")
        (asm "movl (%eax), %eax")
        (asm "movl (%edx), %edx")
        (asm "shldl %cl, %edx, %eax")
        (asm "movl (%esp), %edx")
        (asm "leal (%edx,%ebx,4), %edx")
        (asm "movl %eax, (%edx)")
        (asm "jmp 5b")
        (asm "6:")
        (asm "movl (%esp), %eax")
        (asm "movl (%eax), %edx")
        (asm "shll %cl, %edx")
        (asm "movl %edx, (%eax)")
        (asm "addl $8, %esp")

        (asm "movl 4(%esi), %ebx")
        (asm "movl 8(%ebx), %ecx")
        (asm "movl (%ebx), %ebx")
        (asm "leal -4(%ebx,%ecx,4), %ebx")
        (asm "7:")
        (asm "movl (%ebx), %eax")
        (asm "testl %eax, %eax")
        (asm "jnz 9f")
        (asm "subl $1, %ecx")
        (asm "testl %ecx, %ecx")
        (asm "jz 8f")
        (asm "subl $4, %ebx")
        (asm "jmp 7b")
        (asm "8:")
        (asm "addl $1, %ecx")
        (asm "9:")
        (asm "movl 4(%esi), %ebx")
        (asm "movl %ecx, 4(%ebx)")

        (asm "xorl %edx, %edx")
        (asm "addl $4, %esi")
        (asm "popl %ebx")
        ))
    (bshr () @true (
        (asm "pushl %ebx")

        ; shift (%esi) / 32
        (asm "movl (%esi), %ecx")  ; shift length
        (asm "shrl $5, %ecx")      ; ecx = ecx/32
        (asm "testl %ecx, %ecx")
        (asm "jz 1f")
        (asm "movl 4(%esi), %eax") ; x
        (asm "movl (%eax), %ebx")  ; x.digits
        (asm "movl 4(%eax), %edx") ; x.ndigit
        (asm "subl %ecx, %edx")    ; x.ndigit - ecx
        (asm "2:")
        (asm "cmpl $0, %edx")
        (asm "jle 3f")
        (asm "leal (%ebx,%ecx,4), %eax")
        (asm "movl (%eax), %eax")
        (asm "movl %eax, (%ebx)")
        (asm "addl $4, %ebx")
        (asm "subl $1, %edx")
        (asm "jmp 2b")
        (asm "3:")

        ; clear leading words
        (asm "movl 4(%esi), %eax")  ; x
        (asm "movl (%eax), %ebx")   ; x.digits
        (asm "movl 4(%eax), %edx")  ; x.ndigit
        (asm "4:")
        (asm "testl %ecx, %ecx")
        (asm "jz 1f")
        (asm "subl $1, %ecx")
        (asm "subl $1, %edx")
        (asm "leal (%ebx,%edx,4), %eax")
        (asm "movl $0, (%eax)")
        (asm "jmp 4b")
        (asm "1:")

        ; shift (%esi) % 32
        (asm "subl $8, %esp")
        (asm "movl 4(%esi), %eax")  ; x
        (asm "movl (%eax), %ebx")   ; x.digits
        (asm "movl 4(%eax), %edx")  ; x.ndigit
        (asm "movl (%esi), %ecx")
        (asm "shrl $5, %ecx")
        (asm "subl %ecx, %edx")
        (asm "subl $1, %edx")
        (asm "movl %edx, 4(%esp)")
        (asm "movl $0, (%esp)")
        (asm "movl (%esi), %ecx")
        (asm "andl $0x1f, %ecx")

        ; (%esp):  index
        ; 4(%esp): n-1
        (asm "5:")
        (asm "movl (%esp), %edx")
        (asm "cmpl 4(%esp), %edx")
        (asm "jge 6f")
        (asm "leal (%ebx,%edx,4), %eax")
        (asm "leal 4(%ebx,%edx,4), %edx")
        (asm "movl (%eax), %eax")
        (asm "movl (%edx), %edx")
        (asm "shrdl %cl, %edx, %eax")
        (asm "movl (%esp), %edx")
        (asm "leal (%ebx,%edx,4), %edx")
        (asm "movl %eax, (%edx)")
        (asm "addl $1, (%esp)")
        (asm "jmp 5b")
        (asm "6:")
        (asm "leal (%ebx,%edx,4), %edx")
        (asm "movl (%edx), %eax")
        (asm "shrl %cl, %eax")
        (asm "movl %eax, (%edx)")
        (asm "addl $8, %esp")

        ; update number of digits
        (asm "movl 4(%esi), %ebx")
        (asm "movl 8(%ebx), %ecx")
        (asm "movl (%ebx), %ebx")
        (asm "leal -4(%ebx,%ecx,4), %ebx")
        (asm "7:")
        (asm "movl (%ebx), %eax")
        (asm "testl %eax, %eax")
        (asm "jnz 9f")
        (asm "subl $1, %ecx")
        (asm "testl %ecx, %ecx")
        (asm "jz 8f")
        (asm "subl $4, %ebx")
        (asm "jmp 7b")
        (asm "8:")
        (asm "addl $1, %ecx")
        (asm "9:")
        (asm "movl 4(%esi), %ebx")
        (asm "movl %ecx, 4(%ebx)")

        (asm "xorl %edx, %edx")
        (asm "addl $4, %esi")
        (asm "popl %ebx")
        ))

    (fneg () @true (
        (asm "movl (%esi), %eax")
        (asm "fldl (%eax)")
        (asm "fchs")
        (asm "fstpl (%eax)")
        ))
    (fadd () @true (
        (vmpop %ecx)
        (asm "movl (%esi), %eax")
        (asm "fldl (%ecx)")
        (asm "fldl (%eax)")
        (asm "faddp %st, %st(1)")
        (asm "fstpl (%eax)")
        ))
    (fsub () @true (
        (vmpop %ecx)
        (asm "movl (%esi), %eax")
        (asm "fldl (%ecx)")
        (asm "fldl (%eax)")
        (asm "fsubp %st, %st(1)")
        (asm "fstpl (%eax)")
        ))
    (fmul () @true (
        (vmpop %ecx)
        (asm "movl (%esi), %eax")
        (asm "fldl (%ecx)")
        (asm "fldl (%eax)")
        (asm "fmulp %st, %st(1)")
        (asm "fstpl (%eax)")
        ))
    (fdiv () @true (
        (vmpop %ecx)
        (asm "movl (%esi), %eax")
        (asm "fldl (%ecx)")
        (asm "fldl (%eax)")
        (asm "fdivp %st, %st(1)")
        (asm "fstpl (%eax)")
        ))
    ; integer to float
    (itof () @true (
        (vmsave)
        (call prim_allocate_float)
        (vmrestore)
        (asm "fildl (%esi)")
        (asm "fstpl (%eax)")
        (asm "movl %eax, (%esi)")
        ))

    ; allocate cons object
    ; arg0 = cdr object
    ; arg1 = car object
    (cons () @true (
        (vmsave)
        (call allocate_cons)
        (vmrestore)
        (vmpop %ecx)
        (asm "movl %ecx, (%eax)")
        (asm "movl (%esi), %ecx")
        (asm "movl %ecx, 4(%eax)")
        (asm "movl %eax, (%esi)")
        ))
    ; decompose cons object
    ; arg0 = cons object
    (decons () @true (
        (asm "movl (%esi), %eax")
        (asm "movl 4(%eax), %ecx")
        (asm "movl %ecx, (%esi)")
        (asm "movl (%eax), %eax")
        (vmpush %eax)
        ))
    (list_at () @true (
        (vmpop %ecx)
        (asm "movl (%esi), %eax")
        (asm "0:")
        (asm "testl %ecx, %ecx")
        (asm "jz 1f")
        (asm "movl 4(%eax), %eax")
        (asm "subl $1, %ecx")
        (asm "jmp 0b")
        (asm "1:")
        (asm "movl (%eax), %eax")
        (asm "movl %eax, (%esi)")
        ))
    (list_from () @true (
        (vmpop %ecx)
        (asm "movl (%esi), %eax")
        (asm "0:")
        (asm "testl %ecx, %ecx")
        (asm "jz 1f")
        (asm "movl 4(%eax), %eax")
        (asm "subl $1, %ecx")
        (asm "jmp 0b")
        (asm "1:")
        (asm "movl %eax, (%esi)")
        ))
    (list_len () @true (
        (asm "movl (%esi), %eax")
        (asm "xorl %ecx, %ecx")
        (asm "0:")
        (asm "testl %eax, %eax")
        (asm "jz 1f")
        (asm "movl 4(%eax), %eax")
        (asm "addl $1, %ecx")
        (asm "jmp 0b")
        (asm "1:")
        (asm "movl %ecx, (%esi)")
    ))
    ; allocate plain object
    ; arg0 = size (in bytes)
    ; NB: allocated memory will not be zero-cleared
    (plain (byte) @true (
        (asm "movl (%esi), %eax")
        (vmsave)
        (asm "pushl %eax")
        (vmubyte 1 %eax) ; type of plain
        (asm "pushl %eax")
        (call allocate_pstruct)
        (asm "addl $8, %esp")
        (vmrestore)
        (asm "movl %eax, (%esi)")
        ))
    ; allocate tuple object
    ; opd0 = # of elements (8bit)
    ; opd1 = # of boxed elements (8bit)
    ; NB:
    ;  - allocated memory will not be zero-cleared
    ;  - all boxed elements must be placed first
    (struct (byte byte) @true (
        (vmsave)
        (asm "pushl %esi")
        (vmubyte 2 %eax) ; # of boxed elements
        (asm "pushl %eax")
        (vmubyte 1 %eax) ; # of elements
        (asm "pushl %eax")
        (asm "sall $2, %eax")
        (asm "addl %eax, %esi")
        (call allocate_struct_with_values)
        (asm "addl $12, %esp")
        (vmrestore)
        (vmpush %eax)
        ))
    ; allocate variant object
    ; opd0 = tag (16bit)
    ; opd1 = # of elements (8bit)
    ; opd2 = # of boxed elements (8bit)
    ; NB:
    ;  - allocated memory will not be zero-cleared
    ;  - field0 is for the tag
    ;  - do not rewrite the tag
    ;  - all boxed elements must be placed first
    (variant (short byte byte) @true (
        (vmsave)
        (asm "pushl %esi")
        (vmubyte 4 %eax) ; # of boxed elements
        (asm "pushl %eax")
        (vmubyte 3 %eax) ; # of elements
        (asm "pushl %eax")
        (asm "sall $2, %eax")
        (asm "addl %eax, %esi")
        (vmushort 1 %eax) ; tag
        (asm "pushl %eax")
        (call allocate_variant_with_values)
        (asm "addl $16, %esp")
        (vmrestore)
        (vmpush %eax)
        ))
    (field_get0 () @true @(gen_field_get 0)) ; also used for 'car'
    (field_get1 () @true @(gen_field_get 1)) ; also used for 'cdr'
    (field_get2 () @true @(gen_field_get 2))
    (field_get3 () @true @(gen_field_get 3))
    (field_get4 () @true @(gen_field_get 4))
    (field_get5 () @true @(gen_field_get 5))
    (field_get  (byte) @true (
        (vmubyte 1 %eax)
        (asm "sall $2, %eax")
        (asm "movl (%esi), %ecx")
        (asm "addl %ecx, %eax")
        (asm "movl (%eax), %eax")
        (asm "movl %eax, (%esi)")
        ))
    ; field_set obj val
    (field_set0 () @true @(gen_field_set 0)) ; also used for 'setcar'
    (field_set1 () @true @(gen_field_set 1)) ; also used for 'setcdr'
    (field_set2 () @true @(gen_field_set 2))
    (field_set3 () @true @(gen_field_set 3))
    (field_set4 () @true @(gen_field_set 4))
    (field_set5 () @true @(gen_field_set 5))
    (field_set  (byte) @true (
        (vmubyte 1 %eax) ; index
        (asm "sall $2, %eax")
        (vmpop %ecx) ; obj
        (asm "addl %eax, %ecx")
        (asm "movl (%esi), %eax")
        (asm "movl %eax, (%ecx)")
        ))
    ; array nelem
    (array () @true (
        (asm "movl (%esi), %eax") ; # of elements
        (vmsave)
        (asm "pushl %eax")
        (call prim_allocate_array)
        (asm "addl $4, %esp")
        (vmrestore)
        (asm "movl %eax, (%esi)")
        ))
    ; array_get ary idx
    (array_get8 () @true (
        (vmpop %eax) ; index
        (asm "movl (%esi), %ecx") ; array
        (asm "addl %eax, %ecx")
        (asm "movsbl (%ecx), %eax")
        (asm "movl %eax, (%esi)")
        ))
    (array_get16 () @true (
        (vmpop %eax) ; index
        (asm "sall $1, %eax")
        (asm "movl (%esi), %ecx") ; array
        (asm "addl %eax, %ecx")
        (asm "movswl (%ecx), %eax")
        (asm "movl %eax, (%esi)")
        ))
    (array_get32 () @true (
        (vmpop %eax) ; index
        (asm "sall $2, %eax")
        (asm "movl (%esi), %ecx") ; array
        (asm "addl %eax, %ecx")
        (asm "movl (%ecx), %eax")
        (asm "movl %eax, (%esi)")
        ))
    ; array_get ary idx
    (array_getu8 () @true (
        (vmpop %eax) ; index
        (asm "movl (%esi), %ecx") ; array
        (asm "addl %eax, %ecx")
        (asm "movzbl (%ecx), %eax")
        (asm "movl %eax, (%esi)")
        ))
    (array_getu16 () @true (
        (vmpop %eax) ; index
        (asm "sall $1, %eax")
        (asm "movl (%esi), %ecx") ; array
        (asm "addl %eax, %ecx")
        (asm "movzwl (%ecx), %eax")
        (asm "movl %eax, (%esi)")
        ))
    ; array_set ary idx val
    (array_set8 () @true (
        (asm "movl 4(%esi), %eax") ; index
        (asm "movl 8(%esi), %ecx") ; array
        (asm "addl %eax, %ecx")
        (asm "movl (%esi), %eax") ; value
        (asm "movb %al, (%ecx)")
        (asm "addl $12, %esi")
        ))
    (array_set16 () @true (
        (asm "movl 4(%esi), %eax") ; index
        (asm "sall $1, %eax")
        (asm "movl 8(%esi), %ecx") ; array
        (asm "addl %eax, %ecx")
        (asm "movl (%esi), %eax") ; value
        (asm "movw %ax, (%ecx)")
        (asm "addl $12, %esi")
        ))
    (array_set32 () @true (
        (asm "movl 4(%esi), %eax") ; index
        (asm "sall $2, %eax")
        (asm "movl 8(%esi), %ecx") ; array
        (asm "addl %eax, %ecx")
        (asm "movl (%esi), %eax") ; value
        (asm "movl %eax, (%ecx)")
        (asm "addl $12, %esi")
        ))
    ; allocate stack area for local variables
    (allocate (byte) @true (
        (vmubyte 1 %eax)
        (asm "sall $2, %eax")
        (asm "subl %eax, %esi")
        ))
    (deallocate (byte) @true (
        (vmubyte 1 %eax)
        (asm "movl (%esi), %ecx")
        (asm "movl %ecx, (%esi, %eax, 4)")
        (asm "sall $2, %eax")
        (asm "addl %eax, %esi")
        ))
    ; number of arguments
    (arity () @true (
        (asm "movl 8(%edi), %eax") ; %eax = 4 * arity
        (asm "shrl $2, %eax")
        (vmpush %eax)
        ))
    ; arguments
    (args () @true (
        (asm "subl $12, %esp")
        (asm "movl 8(%edi), %ecx") ; %ecx = 4 * arity
        (asm "leal 8(%edi,%ecx,1), %eax")
        (asm "movl %eax, (%esp)")
        (asm "shrl $2, %ecx")
        (asm "movl %ecx, 8(%esp)")
        (asm "movl $0, 4(%esp)")
        (asm "1:")
        (asm "movl 8(%esp), %ecx")
        (asm "test %ecx, %ecx")
        (asm "jz 2f")
        (vmsave)
        (call allocate_cons)
        (vmrestore)
        (asm "movl 4(%esp), %edx")
        (asm "movl %edx, 4(%eax)")
        (asm "movl (%esp), %edx")
        (asm "movl (%edx), %edx")
        (asm "movl %edx, (%eax)")
        (asm "movl %eax, 4(%esp)")
        (asm "subl $4, (%esp)")
        (asm "subl $1, 8(%esp)")
        (asm "jmp 1b")
        (asm "2:")
        (asm "movl 4(%esp), %eax")
        (asm "addl $12, %esp")
        (asm "xorl %edx, %edx")
        (vmpush %eax)
        ))
    (arg0 () @true ((asm "movl 12(%edi), %eax") (vmpush %eax)))
    (arg1 () @true ((asm "movl 16(%edi), %eax") (vmpush %eax)))
    (arg2 () @true ((asm "movl 20(%edi), %eax") (vmpush %eax)))
    (arg3 () @true ((asm "movl 24(%edi), %eax") (vmpush %eax)))
    (arg4 () @true ((asm "movl 28(%edi), %eax") (vmpush %eax)))
    ; load word from local
    (loadl0 () @true ((asm "movl -4(%edi), %eax") (vmpush %eax)))
    (loadl1 () @true ((asm "movl -8(%edi), %eax") (vmpush %eax)))
    (loadl2 () @true ((asm "movl -12(%edi), %eax") (vmpush %eax)))
    (loadl3 () @true ((asm "movl -16(%edi), %eax") (vmpush %eax)))
    (loadl4 () @true ((asm "movl -20(%edi), %eax") (vmpush %eax)))
    (loadl5 () @true ((asm "movl -24(%edi), %eax") (vmpush %eax)))
    (loadl (byte) @true (
        (vmsbyte 1 %ecx) ; offset
        (asm "leal (%edi,%ecx,1), %eax")
        (asm "movl (%eax), %eax")
        (vmpush %eax)
        ))
    ; store word to local
    (storel0 () @true ((asm "movl (%esi), %eax") (asm "movl %eax, -4(%edi)")))
    (storel1 () @true ((asm "movl (%esi), %eax") (asm "movl %eax, -8(%edi)")))
    (storel2 () @true ((asm "movl (%esi), %eax") (asm "movl %eax, -12(%edi)")))
    (storel3 () @true ((asm "movl (%esi), %eax") (asm "movl %eax, -16(%edi)")))
    (storel4 () @true ((asm "movl (%esi), %eax") (asm "movl %eax, -20(%edi)")))
    (storel5 () @true ((asm "movl (%esi), %eax") (asm "movl %eax, -24(%edi)")))
    (storel (byte) @true (
        (vmsbyte 1 %ecx) ; index
        (asm "leal (%edi,%ecx,1), %eax")
        (asm "movl (%esi), %ecx")
        (asm "movl %ecx, (%eax)")
        ))
    (incrl0 () @true ((asm "addl $1, -4(%edi)")))
    (incrl1 () @true ((asm "addl $1, -8(%edi)")))
    (incrl2 () @true ((asm "addl $1, -12(%edi)")))
    (incrl3 () @true ((asm "addl $1, -16(%edi)")))
    (incrl4 () @true ((asm "addl $1, -20(%edi)")))
    (incrl5 () @true ((asm "addl $1, -24(%edi)")))
    (incrl (byte) @true (
        (vmsbyte 1 %ecx) ; index
        (asm "leal (%edi,%ecx,1), %eax")
        (asm "addl $1, (%eax)")
        ))
    (decrl0 () @true ((asm "subl $1, -4(%edi)")))
    (decrl1 () @true ((asm "subl $1, -8(%edi)")))
    (decrl2 () @true ((asm "subl $1, -12(%edi)")))
    (decrl3 () @true ((asm "subl $1, -16(%edi)")))
    (decrl4 () @true ((asm "subl $1, -20(%edi)")))
    (decrl5 () @true ((asm "subl $1, -24(%edi)")))
    (decrl (byte) @true (
        (vmsbyte 1 %ecx) ; index
        (asm "leal (%edi,%ecx,1), %eax")
        (asm "subl $1, (%eax)")
        ))
    (addrl (byte) @true (
        (vmsbyte 1 %ecx) ; index
        (asm "leal (%edi,%ecx,1), %eax")
        (vmpush %eax)
        ))
    ; load byte from value area
    (loadbv (ushort) @true (
        (vmushort 1 %eax)
        (asm "addl value_area_base, %eax")
        (asm "movsbl (%eax), %eax")
        (vmpush %eax)
        ))
    ; load word from value area
    (loadv (ushort) @true (
        (vmushort 1 %eax)
        (asm "addl value_area_base, %eax")
        (asm "movl (%eax), %eax")
        (vmpush %eax)
        ))
    ; load address of array from value area
    (loadav (ushort) @true (
        (vmushort 1 %eax)
        (asm "addl value_area_base, %eax")
        (vmpush %eax)
        ))
    ; store byte to value area
    (storebv (ushort) @true (
        (vmushort 1 %eax)
        (asm "addl value_area_base, %eax")
        (asm "movl (%esi), %ecx")
        (asm "movb %cl, (%eax)")
        ))
    ; store word to value area
    (storewv (ushort) @true (
        (vmushort 1 %eax)
        (asm "addl value_area_base, %eax")
        (asm "movl (%esi), %ecx")
        (asm "movl %ecx, (%eax)")
        ))
    ; load global heap object
    (loado (ushort) @true (
        (vmushort 1 %eax)
        (asm "shll $2, %eax")
        (asm "addl gobject_area_base, %eax")
        (asm "movl (%eax), %eax")
        (vmpush %eax)
        ))
    ; store global heap object
    (storeo (ushort) @true (
        (vmushort 1 %eax)
        (asm "shll $2, %eax")
        (asm "addl gobject_area_base, %eax")
        (asm "movl (%esi), %ecx")
        (asm "movl %ecx, (%eax)")
        ))
    ; 'fun:1' 'relative address of the function:2'
    (fun (addr) @true (
        (vmsshort 1 %eax) ; offset of address of the function
        (asm "addl %ebx, %eax") ; compute absloute address
        (asm "subl code_base, %eax")
        (vmpush %eax)
        ))
    ; 'lfun:1' 'relative address of the function:4'
    (lfun (laddr) @true (
        (vmint 1 %eax) ; offset of address of the function
        (asm "addl %ebx, %eax") ; compute absloute address
        (asm "subl code_base, %eax")
        (vmpush %eax)
        ))
    ; 'prim:1' 'index of the external function:2'
    (prim (prim) @true (
        (vmushort 1 %eax) ; index of the function
        (asm "orl  $0x80000000, %eax") ; set flag
        (vmpush %eax)
        ))
    (push (object) @true (
        (vmint 1 %eax)
        (vmpush %eax)
        ))
    ; 'call:1' 'relative address of the function:2' 'size of arguments:1'
    (call (addr byte) @nil  (
        (vmubyte 3 %eax)
        (vmpush %eax) ; store size of arguments
        (asm "movl %ebx, %eax")
        (asm "addl $4, %eax")
        (vmpush %eax) ; store return point
        (vmpush %edi) ; store base pointer
        (asm "movl %esi, %edi") ; set base pointer
        (vmsshort 1 %eax) ; offset of address of the function
        (asm "addl %eax, %ebx")
        (vmfetch)
        ))
    ; 'lcall:1' 'relative address of the function:4' 'size of arguments:1'
    (lcall (laddr byte) @nil (
        (vmubyte 5 %eax)
        (vmpush %eax) ; store size of arguments
        (asm "movl %ebx, %eax")
        (asm "addl $6, %eax")
        (vmpush %eax) ; store return point
        (vmpush %edi) ; store base pointer
        (asm "movl %esi, %edi") ; set base pointer
        (vmint 1 %eax) ; offset of address of the function
        (asm "addl %eax, %ebx")
        (vmfetch)
        ))
    ; 'pcall:1' 'index of the external function:2' 'size of arguments:1'
    (pcall (prim byte) @true (
        (vmsave)
        (vmushort 1 %eax)
        (vmubyte 3 %ecx)
        (asm "pushl %esi") ; push argv
        (asm "pushl %ecx") ; push argsize
        (asm "pushl %eax") ; push index
        (call vm_pcall)
        (asm "addl $12, %esp")
        (vmrestore)
        (vmubyte 3 %ecx) ; total size of arguments
        (asm "addl %ecx, %esi") ; remove arguments from stack
        (vmpush %eax) ; push return value
        ))
    ; 'dcall:1' 'size of arguments:1'
    (dcall (byte) @nil (
        (asm "movl (%esi), %eax")
        (if (< (register %eax) 0) ; check flag
            ( ; call primitive function
                (vmpop %eax)
                (asm "movzwl %ax, %eax") ; function index is 2byte value
                (vmubyte 1 %ecx)
                (vmsave)
                (asm "pushl %esi") ; push argv
                (asm "pushl %ecx") ; push argsize
                (asm "pushl %eax") ; push index
                (call vm_pcall)
                (asm "addl $12, %esp")
                (vmrestore)
                (vmubyte 1 %ecx) ; total size of arguments
                (asm "addl %ecx, %esi") ; remove arguments from stack
                (vmpush %eax) ; push return value
            )
            ( ; absolute call
                (asm "movl %ebx, %ecx")
                (asm "addl $2, %ecx")
                (vmubyte 1 %eax)
                (vmpop %ebx)
                (vmpush %eax) ; store size of arguments
                (vmpush %ecx) ; store return point
                (vmpush %edi) ; store base pointer
                (asm "movl %esi, %edi") ; set base pointer
                (asm "addl code_base, %ebx")
                (vmfetch)
            ))
        ))
    ; 'jcall:1' 'size of arguments:1'
    (jcall (byte) @nil (
        (asm "movl %ebx, %ecx")
        (asm "addl $2, %ecx")
        (vmubyte 1 %eax)
        (vmpop %ebx)
        (asm "movl (%ebx), %ebx") ; pointer to the bytecode
        (vmpush %eax) ; store size of arguments
        (vmpush %ecx) ; store return point
        (vmpush %edi) ; store base pointer
        (asm "movl %esi, %edi") ; set base pointer
        (vmfetch)
        ))
    (jjump () @nil (
        (vmpop %ebx)
        (asm "movl (%ebx), %ebx") ; pointer to the bytecode
        (vmfetch)
        ))
    (return () @nil  (
        (asm "xorl %ecx, %ecx") ; return value
        (asm "movl %edi, %esi")
        (vmpop %edi) ; base pointer
        (vmpop %ebx) ; return address
        (vmpop %eax) ; total size of arguments
        (asm "addl %eax, %esi")
        (vmpush %ecx) ; push return value
        (vmfetch)
        ))
    (ireturn () @nil  (
        (asm "movl (%esi), %ecx") ; return value
        (asm "movl %edi, %esi")
        (vmpop %edi) ; base pointer
        (vmpop %ebx) ; return address
        (vmpop %eax) ; total size of arguments
        (asm "addl %eax, %esi")
        (vmpush %ecx) ; push return value
        (vmfetch)
        ))
    ; switch (table search)
    (tswitch (ushort) @nil (
        (vmpop %eax)
        (vmushort 1 %ecx) ; number of cases
        (asm "cmpl %eax, %ecx")
        (asm "cmovle %ecx, %eax")
        (asm "cmpl %eax, %edx")
        (asm "cmova %ecx, %eax")
        (asm "sall $1, %eax")
        (asm "addl $3, %ebx")
        (asm "addl %eax, %ebx")
        (asm "movzwl (%ebx), %eax")
        (asm "addl %eax, %ebx")
        (vmfetch)
        ))
    ; switch (linear search)
    (lswitch (int) @nil (
        (vmpop %eax)
        (vmint 1 %ecx) ; maximum value of case values
        (asm "addl $5, %ebx")
        (asm "1:")
        (asm "movl (%ebx), %edx") ; case value
        (asm "cmpl %eax, %edx")
        (asm "je 2f")
        (asm "cmpl %ecx, %edx")
        (asm "je 2f")
        (asm "addl $6, %ebx")
        (asm "jmp 1b")
        (asm "2:")
        (asm "xorl %edx, %edx") ; zero clear
        (asm "movzwl 4(%ebx), %eax")
        (asm "addl %eax, %ebx")
        (vmfetch)
        ))
    (goto       (addr) @nil ((vmsshort 1 %eax) (asm "addl %eax, %ebx") (vmfetch)))
    (if_zero    (addr) @nil @(gen_comparison1 "cmovz"))
    (if_nonzero (addr) @nil @(gen_comparison1 "cmovnz"))
    (if_eq      (addr) @nil @(gen_comparison2 "cmove"))
    (if_ne      (addr) @nil @(gen_comparison2 "cmovne"))
    (if_gt      (addr) @nil @(gen_comparison2 "cmovg"))
    (if_ge      (addr) @nil @(gen_comparison2 "cmovge"))
    (if_lt      (addr) @nil @(gen_comparison2 "cmovl"))
    (if_le      (addr) @nil @(gen_comparison2 "cmovle"))
    (if_ugt     (addr) @nil @(gen_comparison2 "cmova"))
    (if_uge     (addr) @nil @(gen_comparison2 "cmovae"))
    (if_ult     (addr) @nil @(gen_comparison2 "cmovb"))
    (if_ule     (addr) @nil @(gen_comparison2 "cmovbe"))

    (if_feq     (addr) @nil @(gen_comparison3 "je"))
    (if_fne     (addr) @nil @(gen_comparison3 "jne"))
    (if_fgt     (addr) @nil @(gen_comparison3 "ja"))
    (if_fge     (addr) @nil @(gen_comparison3 "jae"))
    (if_flt     (addr) @nil @(gen_comparison3 "jb"))
    (if_fle     (addr) @nil @(gen_comparison3 "jbe"))

    ; instructions for handling exceptions.
    ; push unwind stack
    (unwind_push (addr) @true (
        (vmsshort 1 %eax)
        (asm "addl %ebx, %eax") ; address of handler
        (asm "pushl %eax")
        (asm "pushl %esi")
        (asm "pushl %edi")
        (vmsave)
        (asm "pushl $8")
        (asm "pushl $" @PLAIN_OTHER)
        (call allocate_pstruct)
        (asm "addl $8, %esp")
        (vmrestore)
        (asm "movl %esp, (%eax)")
        (asm "movl exstack, %ecx")
        (asm "movl %ecx, 4(%eax)")
        (asm "movl %eax, exstack")
        ))
    ; pop unwind stack
    (unwind_pop () @true (
        (asm "addl $12, %esp")
        (asm "movl exstack, %eax")
        (asm "movl 4(%eax), %eax")
        (asm "movl %eax, exstack")
        ))
    ; throw given value
    (throw () @nil (
        (vmpop %ecx)    ; exception value
        (asm "movl exstack, %eax")
        (asm "movl (%eax), %esp")
        (asm "movl 4(%eax), %eax")
        (asm "movl %eax, exstack")
        (asm "popl %edi")
        (asm "popl %esi")
        (asm "popl %ebx")
        (vmpush %ecx)
        (vmfetch)
        ))

    (exit () @nil ((vmpop %eax) (break)))

    (check_int  (addr) @nil (
        (vmpop %eax)
        (vmsshort 1 %ecx)
        (asm "andl $1, %eax")
        (asm "movl $3, %eax")
        (asm "cmovz %ecx, %eax")
        (vmsucc %eax)
        (vmfetch)
        ))
    (check_string (addr) @nil @(gen_check_pstruct PLAIN_STRING))
    (check_list (addr int) @nil (
        ; XXX: should not hardcode the layout of object header.
        (vmpop %eax)
        (vmint 3 %ecx)
        (asm "0:")
        (asm "testl %eax, %eax")
        (asm "jz 1f")
        (asm "testl $1, %eax") ; if 1 & %eax != 0 then %eax is a boxed integer.
        (asm "jnz 3f")
        (asm "movl -4(%eax), %edx") ; %edx <- header of %eax
        (asm "andl $7, %edx")
        (asm "cmpl $" @TAG_CONS ", %edx")
        (asm "jne 3f")
        (asm "movl 4(%eax), %eax") ; %eax <- cdr %eax
        (asm "subl $1, %ecx")
        (asm "jmp 0b")
        (asm "1:")
        (asm "testl %ecx, %ecx")
        (asm "jz 2f")
        (asm "3:") ; here, %eax is not a list of length %ecx.
        (asm "xorl %edx, %edx")
        (vmsshort 1 %ecx)
        (vmsucc %ecx)
        (vmfetch)
        (asm "2:")
        (asm "xorl %edx, %edx")
        (vmsucc 7)
        (vmfetch)
        ))
    (check_list2 (addr int) @nil (
        ; XXX: should not hardcode the layout of object header.
        (vmpop %eax)
        (vmint 3 %ecx)
        (asm "0:")
        (asm "testl %eax, %eax")
        (asm "jz 1f")
        (asm "testl %ecx, %ecx")
        (asm "jz 2f")
        (asm "testl $1, %eax") ; if 1 & %eax != 0 then %eax is a boxed integer.
        (asm "jnz 3f")
        (asm "movl -4(%eax), %edx") ; %edx <- header of %eax
        (asm "andl $7, %edx")
        (asm "cmpl $" @TAG_CONS ", %edx")
        (asm "jne 3f")
        (asm "movl 4(%eax), %eax") ; %eax <- cdr %eax
        (asm "subl $1, %ecx")
        (asm "Jmp 0b")
        (asm "1:")
        (asm "testl %ecx, %ecx")
        (asm "jnz 3f")
        (asm "2:")
        (asm "xorl %edx, %edx")
        (vmsucc 7)
        (vmfetch)
        (asm "3:")
        (asm "xorl %edx, %edx")
        (vmsshort 1 %ecx)
        (vmsucc %ecx)
        (vmfetch)
        ))
    ))

; insn-name -> (code len)
(var vm_insn_table (do
    (var code 0)
    (var entries ())
    (foreach i vm_instructions (do
        (var name (car i))
        (var len  (insn_length (cadr i)))
        (push entries `(@name @code @len))
        (incr code)
        ))
    (reverse entries)

    ))

(define IS_PRIM (v) `(< @v 0))
(define PRIM_IDX (v) `(& @v 0xffff))
